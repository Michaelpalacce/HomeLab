---
- hosts: all
  name: Setup prereqs
  become: yes
  any_errors_fatal: yes
  tags:
      - preflight
  vars_files:
      - "./vars/main.yml"
  roles:
      - michaelpalacce.helm
      - michaelpalacce.kubernetes_preflight

- hosts: all
  name: Setup Logs and log sizes
  become: yes
  gather_facts: false
  tags:
      - preflight
      - preflight-kubelet
  vars_files:
      - "./vars/main.yml"
  tasks:
      - name: Stop kubelet
        systemd:
            state: stopped
            name: kubelet

      - name: Disable kubelet
        shell: systemctl disable kubelet

- hosts: all
  name: Setup Logs and log sizes
  gather_facts: false
  become: yes
  tags:
      - preflight
      - preflight-logs
  vars_files:
      - "./vars/main.yml"
  tasks:
      - name: Logrotate
        copy:
            dest: "{{ item.dest }}"
            src: "{{ item.src }}"
        with_items:
            - dest: /etc/logrotate.d/allContainerLogs
              src: allContainerLogs
            - dest: /etc/logrotate.d/cniLogs
              src: cniLogs
            - dest: /etc/logrotate.d/podLogs
              src: podLogs

      - name: Limit Journalctl max size
        command: "journalctl --vacuum-size={{ journalctl_vaccum_size }}"
        register: logrotate_stat

      - name: Check if logrotate is daily
        stat: path=/etc/cron.daily/logrotate
        register: logrotate_stat

      - name: Move logrotate to hourly if daily
        command: mv /etc/cron.daily/logrotate /etc/cron.hourly/logrotate
        when: logrotate_stat.stat.exists

- hosts: all
  name: Setup Storage dependencies
  become: yes
  gather_facts: false
  tags:
      - preflight
      - preflight-storage-dependencies
  vars_files:
      - "./vars/main.yml"
  tasks:
      - name: Ensure dependencies are installed
        apt:
            name: "{{ packages }}"
            state: present
        vars:
            packages:
                - open-iscsi
                - nfs-common
                - jq

- hosts:
    - master
    - workers
  become: true
  any_errors_fatal: true
  tags:
      - setup
      - setup-k3s
  vars_files:
      - "./vars/main.yml"
  roles:
      - xanmanning.k3s

- hosts: master
  name: Setup master k3s calico and fetch config
  become: yes
  tags:
      - setup
      - setup-init-master
  vars_files:
      - "./vars/main.yml"
  tasks:

      - name: Setup k3s and setup calico CNI
        shell: "{{ item }}"
        with_items:
            - mkdir -p ~/.kube
            - cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
            - kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

      - name: Copy output to local files
        fetch:
            src: "{{ item.src }}"
            dest: "{{ item.dest }}"
            flat: yes
        with_items:
            - src: /etc/rancher/k3s/k3s.yaml
              dest: "{{ output_dir }}/config"


- hosts: master
  name: Setup Longhorn storage
  become: yes
  tags:
      - init
      - storage
      - storage-setup-longhorn-system
  vars_files:
      - "./vars/main.yml"
  tasks:
      - name: Cleanup old potential chart
        file:
            path: longhorn-system
            state: absent

      - name: Ensure new Chart is present
        copy:
            src: ../../../Helm/apps/longhorn-system
            dest: .

      - name: Add stable chart repo
        kubernetes.core.helm_repository:
            name: longhorn-system
            repo_url: "https://charts.longhorn.io"

      - name: Install longhorn-system namespace
        kubernetes.core.helm:
            name: longhorn-system
            create_namespace: true
            release_namespace: longhorn-system
            chart_ref: longhorn/longhorn
            values_files: longhorn-system/values.yaml

      - name: Cleanup chart, we no longer need this
        file:
            path: longhorn-system
            state: absent

      - name: Verify everything is in state Running ( This may take a LONG time if you don't have the images and your internet is slow )
        shell: kubectl get po -n longhorn-system | awk '{ print $3 }'
        register: storage_pods_running
        until: storage_pods_running.stdout.find("ContainerCreating") == -1 and storage_pods_running.stdout.find("BackOff") == -1 and storage_pods_running.stdout.find("Error") == -1 and storage_pods_running.stdout.find("Init") == -1
        retries: 360
        delay: 5
        when: verify_running

- hosts: master
  name: Setup nginxproxymanager
  become: yes
  tags:
      - init
      - nginxproxymanager
      - nginxproxymanager-setup
  tasks:
      - name: Cleanup old potential chart
        file:
            path: nginxproxymanager
            state: absent

      - name: Ensure new Chart is present
        copy:
            src: ../../../Helm/apps/nginxproxymanager
            dest: .

      - name: Install nginxproxymanager namespace
        kubernetes.core.helm:
            name: nginxproxymanager
            create_namespace: false
            release_namespace: kube-system
            chart_ref: nginxproxymanager/
            values_files: nginxproxymanager/values.yaml

      - name: Cleanup chart, we no longer need this
        file:
            path: nginxproxymanager
            state: absent

- hosts: master
  name: Setup cgroup-gc to help cleanup cgroups
  become: yes
  tags:
      - init
      - init_cgroup-gc
      - init_cgroup-gc-setup
  tasks:
      - name: Cleanup old potential chart
        file:
            path: cgroup-gc
            state: absent

      - name: Ensure new Chart is present
        copy:
            src: ../../../Helm/apps/cgroup-gc
            dest: .

      - name: Install cgroup-gc namespace
        kubernetes.core.helm:
            name: cgroup-gc
            create_namespace: true
            release_namespace: cgroup-gc
            chart_ref: cgroup-gc/
            values_files: cgroup-gc/values.yaml

      - name: Cleanup chart, we no longer need this
        file:
            path: cgroup-gc
            state: absent


- hosts: all
  name: Fix Multipath
  become: yes
  tags:
      - init
      - init_multipath
  tasks:
      - name: Make sure multipath conf file is missing
        file:
            path: /etc/multipath.conf
            state: absent

      - name: Copy Multipath File
        copy:
            src: ./files/multipath.conf
            dest: /etc/multipath.conf

      - name: Restart multipath service
        systemd:
            state: restarted
            name: multipathd

- hosts: all
  name: Fix Orphaned Pods
  become: yes
  tags:
      - init
      - init_orphaned
  tasks:
      - name: Make sure multipath conf file is missing
        file:
            path: /home/ubuntu/cleanUpOrphanedPods.py
            state: absent

      - name: Copy cleanUpOrphanedPods File
        copy:
            src: ./files/cleanUpOrphanedPods.py
            dest: /home/ubuntu/cleanUpOrphanedPods.py

      - name: Run in background
        shell:
            cmd: python3 /home/ubuntu/clean.py > /var/log/orphanedPodsCleaner &
